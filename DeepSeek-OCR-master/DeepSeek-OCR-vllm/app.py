import streamlit as st
import os
import tempfile
import asyncio
import re
from pathlib import Path
import shutil
import torch
from PIL import Image, ImageOps
import zipfile
import io
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import fitz  # PyMuPDF

# Page configuration
st.set_page_config(
    page_title="DeepSeek-OCR ç½‘é¡µç•Œé¢",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Title and description
st.title("ğŸ“„ DeepSeek-OCR ç½‘é¡µç•Œé¢")
st.markdown("ä½¿ç”¨ DeepSeek-OCR å°†æ–‡æ¡£å’Œå›¾ç‰‡è½¬æ¢ä¸º Markdown æ ¼å¼")

# Helper functions
def pdf_to_images_high_quality(pdf_path, dpi=144):
    """Convert PDF to high-quality images"""
    images = []
    pdf_document = fitz.open(pdf_path)
    zoom = dpi / 72.0
    matrix = fitz.Matrix(zoom, zoom)

    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)
        Image.MAX_IMAGE_PIXELS = None
        img_data = pixmap.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        if img.mode in ('RGBA', 'LA'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
            img = background
        images.append(img)

    pdf_document.close()
    return images

def re_match(text):
    """Extract reference patterns from OCR output"""
    pattern = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, text, re.DOTALL)

    mathes_image = []
    mathes_other = []
    for a_match in matches:
        if '<|ref|>image<|/ref|>' in a_match[0]:
            mathes_image.append(a_match[0])
        else:
            mathes_other.append(a_match[0])
    return matches, mathes_image, mathes_other

@st.cache_resource
def get_model(model_path, max_concurrency):
    """Initialize and cache the VLLM model"""
    from vllm import LLM
    from vllm.model_executor.models.registry import ModelRegistry
    from deepseek_ocr import DeepseekOCRForCausalLM

    ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)

    llm = LLM(
        model=model_path,
        hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
        block_size=256,
        enforce_eager=False,
        trust_remote_code=True,
        max_model_len=8192,
        swap_space=0,
        max_num_seqs=max_concurrency,
        tensor_parallel_size=1,
        gpu_memory_utilization=0.9,
        disable_mm_preprocessor_cache=True
    )
    return llm

def process_single_image_prep(image, prompt, crop_mode):
    """Prepare a single image for batch processing"""
    from process.image_process import DeepseekOCRProcessor

    cache_item = {
        "prompt": prompt,
        "multi_modal_data": {
            "image": DeepseekOCRProcessor().tokenize_with_images(
                images=[image],
                bos=True,
                eos=True,
                cropping=crop_mode
            )
        },
    }
    return cache_item

# Initialize session state
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'results' not in st.session_state:
    st.session_state.results = None
if 'output_dir' not in st.session_state:
    st.session_state.output_dir = None

# Sidebar for configuration
st.sidebar.header("âš™ï¸ é…ç½®")

# Model mode selection
mode = st.sidebar.selectbox(
    "æ¨¡å‹æ¨¡å¼",
    ["Gundam", "Tiny", "Small", "Base", "Large"],
    index=0,
    help="é€‰æ‹© OCR æ¨¡å‹æ¨¡å¼"
)

# Set mode parameters
mode_configs = {
    "Tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
    "Small": {"base_size": 640, "image_size": 640, "crop_mode": False},
    "Base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
    "Large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
    "Gundam": {"base_size": 1024, "image_size": 640, "crop_mode": True}
}

config = mode_configs[mode]

# Advanced settings
with st.sidebar.expander("é«˜çº§è®¾ç½®"):
    max_crops = st.slider("æœ€å¤§è£å‰ªæ•°", 2, 9, 6, help="æœ€å¤§è£å‰ªæ•°é‡ï¼ˆGPU æ˜¾å­˜æœ‰é™æ—¶å¯é™ä½æ­¤å€¼ï¼‰")
    max_concurrency = st.number_input("æœ€å¤§å¹¶å‘æ•°", 1, 200, 100, help="æœ€å¤§å¹¶å‘è¯·æ±‚æ•°")
    num_workers = st.number_input("å·¥ä½œè¿›ç¨‹æ•°", 1, 128, 64, help="å›¾åƒé¢„å¤„ç†å·¥ä½œè¿›ç¨‹æ•°")
    skip_repeat = st.checkbox("è·³è¿‡é‡å¤é¡µé¢", value=True, help="è·³è¿‡æ²¡æœ‰æ­£ç¡®ç»“æŸæ ‡è®°çš„é¡µé¢")

# Prompt selection
st.sidebar.header("ğŸ“ æç¤ºè¯è®¾ç½®")
prompt_type = st.sidebar.selectbox(
    "æç¤ºè¯ç±»å‹",
    [
        "æ–‡æ¡£è½¬ Markdown",
        "OCR å›¾ç‰‡",
        "è‡ªç”± OCRï¼ˆæ— å¸ƒå±€ï¼‰",
        "è§£æå›¾è¡¨",
        "æè¿°å›¾ç‰‡",
        "è‡ªå®šä¹‰"
    ],
    index=0
)

# Define prompts
prompts = {
    "æ–‡æ¡£è½¬ Markdown": "<image>\n<|grounding|>Convert the document to markdown.",
    "OCR å›¾ç‰‡": "<image>\n<|grounding|>OCR this image.",
    "è‡ªç”± OCRï¼ˆæ— å¸ƒå±€ï¼‰": "<image>\nFree OCR.",
    "è§£æå›¾è¡¨": "<image>\nParse the figure.",
    "æè¿°å›¾ç‰‡": "<image>\nDescribe this image in detail.",
}

if prompt_type == "è‡ªå®šä¹‰":
    prompt = st.sidebar.text_area("è‡ªå®šä¹‰æç¤ºè¯", value="<image>\n<|grounding|>Convert the document to markdown.")
else:
    prompt = prompts[prompt_type]
    st.sidebar.info(f"æç¤ºè¯: {prompt}")

# Model path
model_path = st.sidebar.text_input(
    "æ¨¡å‹è·¯å¾„",
    value="deepseek-ai/DeepSeek-OCR",
    help="HuggingFace æ¨¡å‹è·¯å¾„æˆ–æœ¬åœ°è·¯å¾„"
)

# Main content area
st.header("ğŸ“¤ ä¸Šä¼ æ–‡ä»¶")

# File uploader
uploaded_files = st.file_uploader(
    "é€‰æ‹©å›¾ç‰‡æˆ– PDF æ–‡ä»¶",
    type=["jpg", "jpeg", "png", "pdf"],
    accept_multiple_files=True,
    help="ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªå›¾ç‰‡ï¼ˆJPGã€PNGï¼‰æˆ– PDF æ–‡ä»¶"
)

# Process button
if uploaded_files and not st.session_state.processing:
    if st.button("ğŸš€ å¼€å§‹ OCR å¤„ç†", type="primary", use_container_width=True):
        st.session_state.processing = True
        st.session_state.results = None

        # Create temporary directory for processing
        temp_dir = tempfile.mkdtemp()
        output_dir = os.path.join(temp_dir, "output")
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, "images"), exist_ok=True)

        st.session_state.output_dir = output_dir

        try:
            # Set environment variables
            if torch.version.cuda == '11.8':
                os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"
            os.environ['VLLM_USE_V1'] = '0'
            os.environ["CUDA_VISIBLE_DEVICES"] = '0'

            # Update config values dynamically
            import config as cfg
            cfg.BASE_SIZE = config["base_size"]
            cfg.IMAGE_SIZE = config["image_size"]
            cfg.CROP_MODE = config["crop_mode"]
            cfg.MAX_CROPS = max_crops
            cfg.MAX_CONCURRENCY = max_concurrency
            cfg.NUM_WORKERS = num_workers
            cfg.SKIP_REPEAT = skip_repeat
            cfg.MODEL_PATH = model_path
            cfg.PROMPT = prompt
            cfg.OUTPUT_PATH = output_dir

            progress_bar = st.progress(0)
            status_text = st.empty()

            # Initialize model
            status_text.text("æ­£åœ¨åŠ è½½ DeepSeek-OCR æ¨¡å‹... è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
            try:
                llm = get_model(model_path, max_concurrency)

                # Import necessary modules
                from vllm import SamplingParams
                from process.ngram_norepeat import NoRepeatNGramLogitsProcessor

                # Setup sampling parameters
                logits_processors = [NoRepeatNGramLogitsProcessor(
                    ngram_size=20,
                    window_size=50,
                    whitelist_token_ids={128821, 128822}
                )]

                sampling_params = SamplingParams(
                    temperature=0.0,
                    max_tokens=8192,
                    logits_processors=logits_processors,
                    skip_special_tokens=False,
                    include_stop_str_in_output=True,
                )
            except Exception as e:
                st.error(f"æ¨¡å‹åŠ è½½é”™è¯¯: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
                st.session_state.processing = False
                st.stop()

            results = []

            # Group files by type
            pdf_files = [f for f in uploaded_files if f.name.lower().endswith('.pdf')]
            image_files = [f for f in uploaded_files if f.name.lower().endswith(('.jpg', '.jpeg', '.png'))]

            # Process image files
            if image_files:
                status_text.text(f"æ­£åœ¨å¤„ç† {len(image_files)} å¼ å›¾ç‰‡...")

                all_images = []
                file_names = []

                for uploaded_file in image_files:
                    file_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())

                    image = Image.open(file_path).convert('RGB')
                    all_images.append(image)
                    file_names.append(uploaded_file.name)

                # Prepare batch inputs
                status_text.text("æ­£åœ¨å‡†å¤‡å›¾ç‰‡è¿›è¡Œæ‰¹å¤„ç†...")
                batch_inputs = []
                for image in all_images:
                    batch_input = process_single_image_prep(image, prompt, config["crop_mode"])
                    batch_inputs.append(batch_input)

                # Run batch inference
                status_text.text(f"æ­£åœ¨å¯¹ {len(batch_inputs)} å¼ å›¾ç‰‡è¿›è¡Œ OCR å¤„ç†... è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
                progress_bar.progress(0.3)

                outputs_list = llm.generate(batch_inputs, sampling_params=sampling_params)

                progress_bar.progress(0.7)

                # Process outputs
                for idx, (output, image, filename) in enumerate(zip(outputs_list, all_images, file_names)):
                    status_text.text(f"æ­£åœ¨å¤„ç†è¾“å‡ºç»“æœ: {filename}...")

                    content = output.outputs[0].text

                    # Clean output
                    if '<ï½œendâ–ofâ–sentenceï½œ>' in content:
                        content = content.replace('<ï½œendâ–ofâ–sentenceï½œ>', '')

                    # Save original output
                    result_ori_path = os.path.join(output_dir, f"{filename}_ori.mmd")
                    with open(result_ori_path, 'w', encoding='utf-8') as f:
                        f.write(content)

                    # Extract and process matches
                    matches_ref, matches_images, mathes_other = re_match(content)

                    # Replace image references
                    for img_idx, a_match_image in enumerate(matches_images):
                        content = content.replace(a_match_image, f'![](images/{idx}_{img_idx}.jpg)\n')

                    # Remove other references
                    for a_match_other in mathes_other:
                        content = content.replace(a_match_other, '').replace('\\coloneqq', ':=').replace('\\eqqcolon', '=:')

                    # Save processed output
                    result_path = os.path.join(output_dir, f"{filename}.mmd")
                    with open(result_path, 'w', encoding='utf-8') as f:
                        f.write(content)

                    results.append({
                        'filename': filename,
                        'type': 'å›¾ç‰‡',
                        'output_file': result_path,
                        'status': 'æˆåŠŸ'
                    })

                progress_bar.progress(0.9)

            # Process PDF files
            if pdf_files:
                for pdf_idx, uploaded_file in enumerate(pdf_files):
                    status_text.text(f"æ­£åœ¨å¤„ç† PDF {uploaded_file.name}... ({pdf_idx+1}/{len(pdf_files)})")

                    file_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())

                    # Convert PDF to images
                    status_text.text(f"æ­£åœ¨å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡: {uploaded_file.name}...")
                    images = pdf_to_images_high_quality(file_path)

                    # Prepare batch inputs
                    status_text.text(f"æ­£åœ¨å‡†å¤‡ {len(images)} é¡µè¿›è¡Œæ‰¹å¤„ç†...")
                    batch_inputs = []
                    for image in images:
                        batch_input = process_single_image_prep(image, prompt, config["crop_mode"])
                        batch_inputs.append(batch_input)

                    # Run batch inference
                    status_text.text(f"æ­£åœ¨å¯¹ {len(images)} é¡µè¿›è¡Œ OCR å¤„ç†... è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
                    outputs_list = llm.generate(batch_inputs, sampling_params=sampling_params)

                    # Process outputs
                    mmd_det_path = os.path.join(output_dir, uploaded_file.name.replace('.pdf', '_det.mmd'))
                    mmd_path = os.path.join(output_dir, uploaded_file.name.replace('.pdf', '.mmd'))

                    contents_det = ''
                    contents = ''
                    jdx = 0

                    for output, img in zip(outputs_list, images):
                        content = output.outputs[0].text

                        if '<ï½œendâ–ofâ–sentenceï½œ>' in content:
                            content = content.replace('<ï½œendâ–ofâ–sentenceï½œ>', '')
                        else:
                            if skip_repeat:
                                continue

                        page_num = f'\n<--- Page {jdx+1} --->'

                        contents_det += content + f'\n{page_num}\n'

                        # Extract and process matches
                        matches_ref, matches_images, mathes_other = re_match(content)

                        # Replace image references
                        for img_idx, a_match_image in enumerate(matches_images):
                            content = content.replace(a_match_image, f'![](images/{jdx}_{img_idx}.jpg)\n')

                        # Remove other references
                        for a_match_other in mathes_other:
                            content = content.replace(a_match_other, '').replace('\\coloneqq', ':=').replace('\\eqqcolon', '=:')

                        contents += content + f'\n{page_num}\n'
                        jdx += 1

                    # Save outputs
                    with open(mmd_det_path, 'w', encoding='utf-8') as f:
                        f.write(contents_det)

                    with open(mmd_path, 'w', encoding='utf-8') as f:
                        f.write(contents)

                    results.append({
                        'filename': uploaded_file.name,
                        'type': 'PDF',
                        'output_file': mmd_path,
                        'status': f'æˆåŠŸï¼ˆå·²å¤„ç† {jdx} é¡µï¼‰'
                    })

            st.session_state.results = results
            progress_bar.progress(1.0)
            status_text.text("âœ… å¤„ç†å®Œæˆï¼")

        except Exception as e:
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

        finally:
            st.session_state.processing = False

# Display results
if st.session_state.results:
    st.header("ğŸ“Š ç»“æœ")

    for result in st.session_state.results:
        with st.expander(f"ğŸ“„ {result['filename']}", expanded=True):
            st.write(f"**ç±»å‹:** {result['type']}")
            st.write(f"**çŠ¶æ€:** {result['status']}")

            if 'output_file' in result and os.path.exists(result['output_file']):
                # Display markdown result
                with open(result['output_file'], 'r', encoding='utf-8') as f:
                    content = f.read()

                col1, col2 = st.columns([3, 1])

                with col1:
                    st.markdown("**é¢„è§ˆ:**")
                    st.text_area("OCR ç»“æœé¢„è§ˆ", content, height=300, key=f"preview_{result['filename']}", label_visibility="collapsed")

                with col2:
                    st.markdown("**ä¸‹è½½:**")
                    st.download_button(
                        label="ä¸‹è½½ç»“æœ",
                        data=content,
                        file_name=os.path.basename(result['output_file']),
                        mime="text/markdown",
                        key=f"download_{result['filename']}"
                    )

    # Download all results
    if st.session_state.output_dir and os.path.exists(st.session_state.output_dir):
        st.markdown("---")

        # Create zip file with all results
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for root, dirs, files in os.walk(st.session_state.output_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, st.session_state.output_dir)
                    zip_file.write(file_path, arcname)

        st.download_button(
            label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰ç»“æœï¼ˆZIPï¼‰",
            data=zip_buffer.getvalue(),
            file_name="ocr_results.zip",
            mime="application/zip",
            type="primary",
            use_container_width=True
        )

# Information section
with st.expander("â„¹ï¸ å…³äº DeepSeek-OCR"):
    st.markdown("""
    ### DeepSeek-OCR ç½‘é¡µç•Œé¢

    è¿™ä¸ªç½‘é¡µç•Œé¢æä¾›äº†ä¸€ä¸ªç®€å•æ˜“ç”¨çš„æ–¹å¼æ¥ä½¿ç”¨ DeepSeek-OCR è¿›è¡Œæ–‡æ¡£å’Œå›¾ç‰‡å¤„ç†ã€‚

    **åŠŸèƒ½ç‰¹æ€§:**
    - æ”¯æŒå›¾ç‰‡ï¼ˆJPGã€PNGï¼‰å’Œ PDF æ–‡ä»¶
    - å¤šç§æ¨¡å‹æ¨¡å¼ï¼ˆTinyã€Smallã€Baseã€Largeã€Gundamï¼‰
    - å¯è‡ªå®šä¹‰æç¤ºè¯ï¼Œé€‚ç”¨äºä¸åŒçš„ OCR ä»»åŠ¡
    - æ”¯æŒæ‰¹å¤„ç†
    - å¯å°†ç»“æœä¸‹è½½ä¸º Markdown æ–‡ä»¶

    **æ¨¡å‹æ¨¡å¼è¯´æ˜:**
    - **Tiny**: å¿«é€Ÿå¤„ç†ç®€å•æ–‡æ¡£
    - **Small**: é€Ÿåº¦å’Œç²¾åº¦å¹³è¡¡
    - **Base**: é€‚ç”¨äºå¤§å¤šæ•°æ–‡æ¡£çš„æ ‡å‡†æ¨¡å¼
    - **Large**: å¤æ‚æ–‡æ¡£çš„é«˜ç²¾åº¦å¤„ç†
    - **Gundam**: é’ˆå¯¹å¤§å‹æ–‡æ¡£ä¼˜åŒ–ï¼Œé‡‡ç”¨è£å‰ªæŠ€æœ¯
    """)

# Footer
st.markdown("---")
st.markdown("åŸºäº Streamlit æ„å»º | ç”± DeepSeek-OCR é©±åŠ¨")
